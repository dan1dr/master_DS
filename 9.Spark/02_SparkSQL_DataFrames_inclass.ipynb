{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "02-SparkSQL-DataFrames.inclass.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TVtfZEvryne"
      },
      "source": [
        "# SparkSQL and DataFrames \n",
        "\n",
        "<a href = \"http://yogen.io\"><img src=\"http://yogen.io/assets/logo.svg\" alt=\"yogen\" style=\"width: 200px; float: right;\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48ULrStfrynh"
      },
      "source": [
        "## RDDs, DataSets, and DataFrames\n",
        "\n",
        "RDDs are the original interface for Spark programming.\n",
        "\n",
        "DataFrames were introduced in 1.3\n",
        "\n",
        "Datasets were introduced in 1.6, and unified with DataFrames in 2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5h1cD9Zryni"
      },
      "source": [
        "### Advantages of DataFrames:\n",
        "\n",
        "from https://www.datacamp.com/community/tutorials/apache-spark-python:\n",
        "\n",
        "> More specifically, the performance improvements are due to two things, which you’ll often come across when you’re reading up DataFrames: custom memory management (project Tungsten), which will make sure that your Spark jobs much faster given CPU constraints, and optimized execution plans (Catalyst optimizer), of which the logical plan of the DataFrame is a part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFJJaBKorynx"
      },
      "source": [
        "## SparkSQL and DataFrames \n",
        "\n",
        "\n",
        "pyspark does not have the Dataset API, which is available only if you use Spark from a statically typed language: Scala or Java.\n",
        "\n",
        "From https://spark.apache.org/docs/2.4.4/sql-programming-guide.html\n",
        "\n",
        "> A DataFrame is a Dataset organized into named columns. It is conceptually equivalent to a table in a relational database or a data frame in R/Python, but with richer optimizations under the hood. DataFrames can be constructed from a wide array of sources such as: structured data files, tables in Hive, external databases, or existing RDDs. The DataFrame API is available in Scala, Java, Python, and R. In Scala and Java, a DataFrame is represented by a Dataset of Rows. In the Scala API, DataFrame is simply a type alias of Dataset[Row]. While, in Java API, users need to use Dataset&lt;Row> to represent a DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4y3VgsLrynx"
      },
      "source": [
        "### The pyspark.sql module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9yc9uznryny"
      },
      "source": [
        "Important classes of Spark SQL and DataFrames:\n",
        "\n",
        "* `pyspark.sql.SparkSession` Main entry point for DataFrame and SQL functionality.\n",
        "\n",
        "* `pyspark.sql.DataFrame` A distributed collection of data grouped into named columns.\n",
        "\n",
        "* `pyspark.sql.Column` A column expression in a DataFrame.\n",
        "\n",
        "* `pyspark.sql.Row` A row of data in a DataFrame.\n",
        "\n",
        "* `pyspark.sql.GroupedData` Aggregation methods, returned by DataFrame.groupBy().\n",
        "\n",
        "* `pyspark.sql.DataFrameNaFunctions` Methods for handling missing data (null values).\n",
        "\n",
        "* `pyspark.sql.DataFrameStatFunctions` Methods for statistics functionality.\n",
        "\n",
        "* `pyspark.sql.functions` List of built-in functions available for DataFrame.\n",
        "\n",
        "* `pyspark.sql.types` List of data types available.\n",
        "\n",
        "* `pyspark.sql.Window` For working with window functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcZnIckLrynz"
      },
      "source": [
        "http://spark.apache.org/docs/2.4.4/api/python/pyspark.sql.html\n",
        "\n",
        "https://spark.apache.org/docs/2.4.4/sql-programming-guide.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wtvXuXrrynz"
      },
      "source": [
        "## SparkSession\n",
        "\n",
        "The traditional way to interact with Spark is the SparkContext. In the notebooks we get that from the pyspark driver.\n",
        "\n",
        "From 2.0 we can use SparkSession to replace SparkConf, SparkContext and SQLContext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O266pJ2Nrynz"
      },
      "source": [
        "### If you are running this notebook in Google Colab\n",
        "\n",
        "Copy the following to a code cell and run it. It will install and set up Spark for you.\n",
        "\n",
        "```python\n",
        "!pip install pyspark==3.1.1\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").config(\"spark.ui.port\", \"4050\").getOrCreate() ## For ngrok to tunnel to\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2LdHNtDryn0",
        "outputId": "52b69bdc-680d-45a8-ee6f-279b2ebee553"
      },
      "source": [
        "!pip install pyspark==3.1.1\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").config(\"spark.ui.port\", \"4050\").getOrCreate() ## For ngrok to tunnel to\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark==3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 71kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 18.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=f16b216b315c08a08798c8f8cb580b1153199b724385db5ca1edfd0dc751e0dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNID3OmPryn0"
      },
      "source": [
        "#### Passing other options to spark session:\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyZ0HuVcryn1",
        "outputId": "a61c6e4e-6a2f-4ce8-a94a-10980f7b8759"
      },
      "source": [
        "spark.sparkContext.getConf().getAll()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('spark.driver.host', '435c62bc596a'),\n",
              " ('spark.executor.id', 'driver'),\n",
              " ('spark.sql.warehouse.dir', 'file:/content/spark-warehouse'),\n",
              " ('spark.app.name', 'pyspark-shell'),\n",
              " ('spark.ui.port', '4050'),\n",
              " ('spark.rdd.compress', 'True'),\n",
              " ('spark.app.id', 'local-1616177659680'),\n",
              " ('spark.serializer.objectStreamReset', '100'),\n",
              " ('spark.master', 'local[*]'),\n",
              " ('spark.submit.pyFiles', ''),\n",
              " ('spark.submit.deployMode', 'client'),\n",
              " ('spark.driver.port', '35025'),\n",
              " ('spark.app.startTime', '1616177658180'),\n",
              " ('spark.ui.showConsoleProgress', 'true')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mebi6xytwdZb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wSwwi--ryn1"
      },
      "source": [
        "We can check option values in the resulting session like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wAmMdNWryn1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tee3LeiDryn2"
      },
      "source": [
        "### Creating DataFrames\n",
        "\n",
        "SparkSession.createDataFrame: from an RDD, a list or a pandas.DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ-5p9ggwpyn",
        "outputId": "2224e5b0-7b1b-4266-8e0a-e4698497f514"
      },
      "source": [
        "import random\n",
        "\n",
        "random.seed(7)\n",
        "ids = range(15)\n",
        "species = random.choices(['capibara', 'naked mole rat', 'axolotl', 'flying fox'], k=15)\n",
        "\n",
        "data = list(zip(ids, species))\n",
        "data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 'naked mole rat'),\n",
              " (1, 'capibara'),\n",
              " (2, 'axolotl'),\n",
              " (3, 'capibara'),\n",
              " (4, 'axolotl'),\n",
              " (5, 'naked mole rat'),\n",
              " (6, 'capibara'),\n",
              " (7, 'axolotl'),\n",
              " (8, 'capibara'),\n",
              " (9, 'naked mole rat'),\n",
              " (10, 'capibara'),\n",
              " (11, 'capibara'),\n",
              " (12, 'naked mole rat'),\n",
              " (13, 'flying fox'),\n",
              " (14, 'capibara')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWYn-qxFryn2",
        "outputId": "f20a7c43-838d-48c5-fc99-ce545d8bb47a"
      },
      "source": [
        "df = spark.createDataFrame(data)\n",
        "df"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[_1: bigint, _2: string]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTlnPwg2x5G5",
        "outputId": "86b07ad8-0e46-417a-b474-baa817efebc2"
      },
      "source": [
        "df.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------------+\n",
            "| _1|            _2|\n",
            "+---+--------------+\n",
            "|  0|naked mole rat|\n",
            "|  1|      capibara|\n",
            "|  2|       axolotl|\n",
            "|  3|      capibara|\n",
            "|  4|       axolotl|\n",
            "|  5|naked mole rat|\n",
            "|  6|      capibara|\n",
            "|  7|       axolotl|\n",
            "|  8|      capibara|\n",
            "|  9|naked mole rat|\n",
            "| 10|      capibara|\n",
            "| 11|      capibara|\n",
            "| 12|naked mole rat|\n",
            "| 13|    flying fox|\n",
            "| 14|      capibara|\n",
            "+---+--------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLmcGAKbyIkI",
        "outputId": "f32b26f6-2fb1-4d81-82a4-790c06ab1b8e"
      },
      "source": [
        "df.take(5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(_1=0, _2='naked mole rat'),\n",
              " Row(_1=1, _2='capibara'),\n",
              " Row(_1=2, _2='axolotl'),\n",
              " Row(_1=3, _2='capibara'),\n",
              " Row(_1=4, _2='axolotl')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e11UADs0yPeQ",
        "outputId": "89346bfc-6888-4ac5-d83c-b116df8b09d6"
      },
      "source": [
        "first_row = df.first()\n",
        "first_row"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(_1=0, _2='naked mole rat')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lp4WK895yS1_",
        "outputId": "6e5e9aeb-850f-42fe-cb8f-0443ae402873"
      },
      "source": [
        "first_row['_2']"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'naked mole rat'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a5eFgFbryn2"
      },
      "source": [
        "### Creating DataFrames\n",
        "\n",
        "* From RDDs\n",
        "* from Hive tables\n",
        "* From Spark sources: parquet (default), json, jdbc, orc, libsvm, csv, text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXgm5-rxryn2"
      },
      "source": [
        "#### From RDDs\n",
        "\n",
        "This is what we did on the previous notebook:\n",
        "\n",
        "```python\n",
        "import re\n",
        "\n",
        "def remove_punctuation(line):\n",
        "    return re.sub('[^a-z0-9 ]', '', line.lower())\n",
        "\n",
        "shakespeare = spark.sparkContext.textFile('shakespeare.txt')\n",
        "\n",
        "freqs = shakespeare.map(remove_punctuation)\\\n",
        "                   .flatMap(str.split)\\\n",
        "                   .map(lambda word: (word, 1))\\\n",
        "                   .reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "479skkWHryn3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrjlVhirryn3"
      },
      "source": [
        "We can put that on a DataFrame in order to further analyze it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loMSj8arryn3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N994rbRryn4"
      },
      "source": [
        "### Inferring and specifying schemas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1T0mBjTryn4",
        "outputId": "d57b9702-1665-41d4-d54c-1028d5ae6c25"
      },
      "source": [
        "df = spark.createDataFrame(data, schema=['id', 'species'])\n",
        "df"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id: bigint, species: string]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGAI9NZYzmGg",
        "outputId": "15428ac8-3f2f-4bd3-af19-44e17f8edbea"
      },
      "source": [
        "from pyspark.sql import types\n",
        "\n",
        "types.StringType()\n",
        "types.IntegerType()\n",
        "types.ShortType()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ShortType"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-LsRfq00BA2",
        "outputId": "8240a198-22b2-4595-89d3-92da820438ee"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- id: long (nullable = true)\n",
            " |-- species: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGwhb0_jryn4"
      },
      "source": [
        "#### Fully specifying a schema\n",
        "\n",
        "We need to create a `StructType` composed of `StructField`s. each of those specifies afiled with name, type and `nullable` properties. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXBDZbEHryn4",
        "outputId": "f6b3a82d-9e08-4087-df32-5c3f46fef8cb"
      },
      "source": [
        "df = spark.createDataFrame(data, schema='id SHORT, species STRING')\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- id: short (nullable = true)\n",
            " |-- species: string (nullable = true)\n",
            "\n",
            "+---+--------------+\n",
            "| id|       species|\n",
            "+---+--------------+\n",
            "|  0|naked mole rat|\n",
            "|  1|      capibara|\n",
            "|  2|       axolotl|\n",
            "|  3|      capibara|\n",
            "|  4|       axolotl|\n",
            "|  5|naked mole rat|\n",
            "|  6|      capibara|\n",
            "|  7|       axolotl|\n",
            "|  8|      capibara|\n",
            "|  9|naked mole rat|\n",
            "| 10|      capibara|\n",
            "| 11|      capibara|\n",
            "| 12|naked mole rat|\n",
            "| 13|    flying fox|\n",
            "| 14|      capibara|\n",
            "+---+--------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uJNlKV61zoR",
        "outputId": "3ea714b3-cb12-4fc9-f237-d33d6569dd58"
      },
      "source": [
        "df.schema"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType(List(StructField(id,ShortType,true),StructField(species,StringType,true)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoNJqG2Lryn5"
      },
      "source": [
        "#### From csv files\n",
        "\n",
        "We can either read them directly into dataframes or read them as RDDs and transform that into a DataFrame. This second way will be very useful if we have unstructured data like web server logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqU0PkOeryn5",
        "outputId": "6f8823d0-5d84-4d26-abfc-dd8ad8af99cf"
      },
      "source": [
        "coupons = spark.read.csv('coupon150720.csv.gz')\n",
        "coupons.show(5)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+---+---+---+---+---+------+---+---+---+----+----+------+----+----+\n",
            "|           _c0|_c1|_c2|_c3|_c4|_c5|   _c6|_c7|_c8|_c9|_c10|_c11|  _c12|_c13|_c14|\n",
            "+--------------+---+---+---+---+---+------+---+---+---+----+----+------+----+----+\n",
            "|79062005698500|  1|MAA|AUH| 9W| 9W| 56.79|USD|  1|  H|   H|0526|150904|  OK|IAF0|\n",
            "|79062005698500|  2|AUH|CDG| 9W| 9W| 84.34|USD|  1|  H|   H|6120|150905|  OK|IAF0|\n",
            "|79062005924069|  1|CJB|MAA| 9W| 9W|  60.0|USD|  1|  H|   H|2768|150721|  OK|IAA0|\n",
            "|79065668570385|  1|DEL|DXB| 9W| 9W|160.63|USD|  2|  S|   S|0546|150804|  OK|INA0|\n",
            "|79065668737021|  1|AUH|IXE| 9W| 9W|152.46|USD|  1|  V|   V|0501|150803|  OK|INA0|\n",
            "+--------------+---+---+---+---+---+------+---+---+---+----+----+------+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-vFob1Pryn5"
      },
      "source": [
        "#### From other types of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aT9LwxRryn6"
      },
      "source": [
        "Apache Parquet is a free and open-source column-oriented data store of the Apache Hadoop ecosystem. It is similar to the other columnar storage file formats available in Hadoop namely RCFile and Optimized RCFile. It is compatible with most of the data processing frameworks in the Hadoop environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_7yxLuCryn6",
        "outputId": "05a94324-64d8-4604-dc70-a0e78363cde3"
      },
      "source": [
        "spark.read.json\n",
        "spark.read.parquet"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrameReader.parquet of <pyspark.sql.readwriter.DataFrameReader object at 0x7f81033ae8d0>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BVZvDoYryn6"
      },
      "source": [
        "### Basic operations with DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOoY_VCQryn6",
        "outputId": "5af7ba58-86b1-4626-9249-c892559a21ed"
      },
      "source": [
        "df.select('id').show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+\n",
            "| id|\n",
            "+---+\n",
            "|  0|\n",
            "|  1|\n",
            "|  2|\n",
            "|  3|\n",
            "|  4|\n",
            "|  5|\n",
            "|  6|\n",
            "|  7|\n",
            "|  8|\n",
            "|  9|\n",
            "| 10|\n",
            "| 11|\n",
            "| 12|\n",
            "| 13|\n",
            "| 14|\n",
            "+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ9bvXWBryn7"
      },
      "source": [
        "### Filtering and selecting\n",
        "\n",
        "Syntax inspired in SQL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KBBdlHWryn7",
        "outputId": "f8cde3fb-0001-46ec-9f1c-8d5736489b30"
      },
      "source": [
        "from pyspark.sql import Column\n",
        "\n",
        "df['id'] > 5"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'(id > 5)'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkGzuta4ryn7"
      },
      "source": [
        "If we want to filter, we will need to build an instance of `Column`, using square bracket notation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV2uH-DVryn7",
        "outputId": "24379100-2c36-478e-b0f9-f9eb97f60145"
      },
      "source": [
        "df.filter(df['id'] > 5).show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------------+\n",
            "| id|       species|\n",
            "+---+--------------+\n",
            "|  6|      capibara|\n",
            "|  7|       axolotl|\n",
            "|  8|      capibara|\n",
            "|  9|naked mole rat|\n",
            "| 10|      capibara|\n",
            "| 11|      capibara|\n",
            "| 12|naked mole rat|\n",
            "| 13|    flying fox|\n",
            "| 14|      capibara|\n",
            "+---+--------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK2QXNNXryn8"
      },
      "source": [
        "That's because a comparison between str and int will error out, so spark will not even get the chance to infer to which column we are referring."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "raises-exception"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "idxDbSFYryn8",
        "outputId": "573d3d3c-d112-41f5-d8e0-8f12f9f3a516"
      },
      "source": [
        "df.filter('id' > 5)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-e66a87b87cf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'str' and 'int'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBLU6R5sryn8"
      },
      "source": [
        "`where` is exactly synonimous with `filter`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_F-OZzRryn8",
        "outputId": "6e6ce0d3-730f-43a7-e698-018e37fa7129"
      },
      "source": [
        "df.where(df['id'] > 5).show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------------+\n",
            "| id|       species|\n",
            "+---+--------------+\n",
            "|  6|      capibara|\n",
            "|  7|       axolotl|\n",
            "|  8|      capibara|\n",
            "|  9|naked mole rat|\n",
            "| 10|      capibara|\n",
            "| 11|      capibara|\n",
            "| 12|naked mole rat|\n",
            "| 13|    flying fox|\n",
            "| 14|      capibara|\n",
            "+---+--------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6O0exBJ5sW-",
        "outputId": "de6ce2f6-aa3d-4466-99c7-688a88691081"
      },
      "source": [
        "df.where((df['id']> 5) & (df['id']<10)).show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------------+\n",
            "| id|       species|\n",
            "+---+--------------+\n",
            "|  6|      capibara|\n",
            "|  7|       axolotl|\n",
            "|  8|      capibara|\n",
            "|  9|naked mole rat|\n",
            "+---+--------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1VrVXlV5_MH",
        "outputId": "9987704f-33d6-442f-eb11-ca4312c1446f"
      },
      "source": [
        "df.filter('id > 5')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id: smallint, species: string]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rbtssuvm6LEJ",
        "outputId": "eb5d09e1-5b8c-4f16-b4e3-c8077894b6d8"
      },
      "source": [
        "df[df['id'] > 5]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id: smallint, species: string]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlfiPsRkryn9"
      },
      "source": [
        "A column is quite different to a Pandas Series. It is just a reference to a column, and can only be used to construct sparkSQL expressions (select, where...). It can't be collected or taken as a one-dimensional sequence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "raises-exception"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "T49Pov3Vryn9",
        "outputId": "0b1f0925-3e75-40b7-bc21-0a63eae929f8"
      },
      "source": [
        "df['id'].show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-1f772950feca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'Column' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r_ayUw18fgN",
        "outputId": "d962abc3-f276-4111-bd6f-1fb7725af27c"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -qq ngrok-stable-linux-amd64.zip\n",
        "get_ipython().system_raw('./ngrok http 4050 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-19 19:24:20--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.192.67.182, 52.206.108.108, 3.216.44.25, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.192.67.182|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  65.6MB/s    in 0.2s    \n",
            "\n",
            "2021-03-19 19:24:20 (65.6 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13773305/13773305]\n",
            "\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "https://4ea560865ad0.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxQUFXn-8uwd",
        "outputId": "73142f4f-0776-40b7-f8ba-5117f7369dd2"
      },
      "source": [
        "df.rdd"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MapPartitionsRDD[90] at javaToPython at NativeMethodAccessorImpl.java:0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvr30E-7ryn-"
      },
      "source": [
        "#### Exercise\n",
        "\n",
        "Extract all zoo animal ids which correspond to capibaras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lT2Dwvt9ryn-",
        "outputId": "5a9688c8-556c-43d8-a4af-cff94c6cf355"
      },
      "source": [
        "df.select('id')\\\n",
        "  .where(df['species']=='capibara')\\\n",
        "  .show()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+\n",
            "| id|\n",
            "+---+\n",
            "|  1|\n",
            "|  3|\n",
            "|  6|\n",
            "|  8|\n",
            "| 10|\n",
            "| 11|\n",
            "| 14|\n",
            "+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnffJ7Y1ryn-"
      },
      "source": [
        "### Adding columns\n",
        "\n",
        "Dataframes are immutable, since they are built on top of RDDs, so we can not assign to them. We need to create new DataFrames with the appropriate columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "raises-exception"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGez28FZryn-",
        "outputId": "dabacb51-a07d-43e9-be19-1d32f818caec"
      },
      "source": [
        "from pyspark.sql import functions\n",
        "\n",
        "df.withColumn('whateva', functions.sqrt('id')).show()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------------+------------------+\n",
            "| id|       species|           whateva|\n",
            "+---+--------------+------------------+\n",
            "|  0|naked mole rat|               0.0|\n",
            "|  1|      capibara|               1.0|\n",
            "|  2|       axolotl|1.4142135623730951|\n",
            "|  3|      capibara|1.7320508075688772|\n",
            "|  4|       axolotl|               2.0|\n",
            "|  5|naked mole rat|  2.23606797749979|\n",
            "|  6|      capibara| 2.449489742783178|\n",
            "|  7|       axolotl|2.6457513110645907|\n",
            "|  8|      capibara|2.8284271247461903|\n",
            "|  9|naked mole rat|               3.0|\n",
            "| 10|      capibara|3.1622776601683795|\n",
            "| 11|      capibara|   3.3166247903554|\n",
            "| 12|naked mole rat|3.4641016151377544|\n",
            "| 13|    flying fox| 3.605551275463989|\n",
            "| 14|      capibara|3.7416573867739413|\n",
            "+---+--------------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "Pd9KIHUH92N3",
        "outputId": "37f1057b-ec7c-4d1d-e560-c5164ec3046b"
      },
      "source": [
        "import math\n",
        "\n",
        "math.log1p(df['id'])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-7e593c69eaa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: must be real number, not Column"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlkluNJUryn_"
      },
      "source": [
        "### User defined functions\n",
        "\n",
        "There are many useful functions in pyspark.sql.functions. These work on columns, that is, they are vectorial.\n",
        "\n",
        "We can write User Defined Functions (`udf`s), which allow us to \"vectorize\" operations: write a standard function to process single elements, then build a udf with that that works on columns in a DataFrame, like a SQL function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXATG2tNryn_",
        "outputId": "1cb6e68f-da69-44ff-de7e-48991a22bfa3"
      },
      "source": [
        "my_new_udf = functions.udf(math.log1p)\n",
        "my_new_udf(df['id'])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'log1p(id)'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUbp8k8m-V9J",
        "outputId": "97042188-8583-489e-ae34-5a9a9d3b9fd8"
      },
      "source": [
        "df.withColumn('yeah_baby',\n",
        "              my_new_udf(df['id'])).show()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------------+------------------+\n",
            "| id|       species|         yeah_baby|\n",
            "+---+--------------+------------------+\n",
            "|  0|naked mole rat|               0.0|\n",
            "|  1|      capibara|0.6931471805599453|\n",
            "|  2|       axolotl|1.0986122886681096|\n",
            "|  3|      capibara|1.3862943611198906|\n",
            "|  4|       axolotl|1.6094379124341003|\n",
            "|  5|naked mole rat| 1.791759469228055|\n",
            "|  6|      capibara|1.9459101490553132|\n",
            "|  7|       axolotl|2.0794415416798357|\n",
            "|  8|      capibara|2.1972245773362196|\n",
            "|  9|naked mole rat| 2.302585092994046|\n",
            "| 10|      capibara|2.3978952727983707|\n",
            "| 11|      capibara|2.4849066497880004|\n",
            "| 12|naked mole rat|2.5649493574615367|\n",
            "| 13|    flying fox| 2.639057329615259|\n",
            "| 14|      capibara|  2.70805020110221|\n",
            "+---+--------------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbQsF9cnryn_"
      },
      "source": [
        "This errors out because \n",
        "\n",
        "```python\n",
        "math.log1p\n",
        "```\n",
        "\n",
        "is not a udf: it doesn't know how to work with strings or Column objects:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "raises-exception"
        ],
        "id": "mb8jd8smryoA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrqaudVmryoA"
      },
      "source": [
        "But we can transform it into a udf:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0w1Z342ryoA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvUE-0omryoA"
      },
      "source": [
        "We can do the same with any function we dream up:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nzp8Qgr1ryoA",
        "outputId": "c6217067-9b64-4ef5-f243-36f0d4b81d96"
      },
      "source": [
        "very_specific_function = functions.udf(lambda word: word[::2])\n",
        "\n",
        "df.select('*', \n",
        "          very_specific_function('species')).show()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------------+-----------------+\n",
            "| id|       species|<lambda>(species)|\n",
            "+---+--------------+-----------------+\n",
            "|  0|naked mole rat|          nkdml a|\n",
            "|  1|      capibara|             cpbr|\n",
            "|  2|       axolotl|             aool|\n",
            "|  3|      capibara|             cpbr|\n",
            "|  4|       axolotl|             aool|\n",
            "|  5|naked mole rat|          nkdml a|\n",
            "|  6|      capibara|             cpbr|\n",
            "|  7|       axolotl|             aool|\n",
            "|  8|      capibara|             cpbr|\n",
            "|  9|naked mole rat|          nkdml a|\n",
            "| 10|      capibara|             cpbr|\n",
            "| 11|      capibara|             cpbr|\n",
            "| 12|naked mole rat|          nkdml a|\n",
            "| 13|    flying fox|            fyn o|\n",
            "| 14|      capibara|             cpbr|\n",
            "+---+--------------+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pI_9F_mryoB"
      },
      "source": [
        "If we want the resulting columns to be of a particular type, we need to specify the return type. This is because in Python return types can not be inferred."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tsq2KhnPryoB",
        "outputId": "38e1e041-492f-4721-c736-26126f04ea20"
      },
      "source": [
        "df.withColumn('yeah_baby',\n",
        "              my_new_udf(df['id']))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id: smallint, species: string, yeah_baby: string]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYAubn3C_uvx",
        "outputId": "d3504189-e6c0-492c-a6fa-6b92712c6409"
      },
      "source": [
        "typed_udf = functions.udf(math.log1p, returnType=types.FloatType())\n",
        "df.withColumn('yeah_baby',\n",
        "              typed_udf(df['id']))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id: smallint, species: string, yeah_baby: float]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzR3kDlZAYRI",
        "outputId": "a1cb1740-61a4-4e1d-da02-9a23ccb10cd5"
      },
      "source": [
        "@functions.udf('float')\n",
        "def myfun(a): \n",
        "  return math.log1p(a)\n",
        "\n",
        "df.select(myfun('id')).show()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|myfun(id)|\n",
            "+---------+\n",
            "|      0.0|\n",
            "|0.6931472|\n",
            "|1.0986123|\n",
            "|1.3862944|\n",
            "| 1.609438|\n",
            "|1.7917595|\n",
            "|1.9459101|\n",
            "|2.0794415|\n",
            "|2.1972246|\n",
            "|2.3025851|\n",
            "|2.3978953|\n",
            "|2.4849067|\n",
            "|2.5649493|\n",
            "|2.6390574|\n",
            "|2.7080503|\n",
            "+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z68g0t-ryoB"
      },
      "source": [
        "Think about this function: what is its return type?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NBu69qkryoB"
      },
      "source": [
        "def x(a, b):\n",
        "  return a + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK67hrrcryoC"
      },
      "source": [
        "#### Exercise: \n",
        "\n",
        "Create a 'body_weight' field in our df. make it 18 for naked mole rat, 25000 for capibaras and 14 for axolotls, and 8000 for flying foxes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akQvmUQdE7Vg",
        "outputId": "eb391724-b643-4b7f-9238-814d7fa7cac8"
      },
      "source": [
        "@functions.udf('int')\n",
        "def body_weight(animal):\n",
        "  weights = {'naked mole rat' : 18,\n",
        "             'capibara' : 25000,\n",
        "             'axolotl' : 14,\n",
        "             'flying fox' : 8000}\n",
        "\n",
        "  return weights.get(animal)\n",
        "\n",
        "df2 = df.withColumn('bw', body_weight('species'))\n",
        "df2"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id: smallint, species: string, bw: int]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eaxbXxUryoC"
      },
      "source": [
        "If we have a column that is not the desired type, we can convert it after the fact with `.cast()`. We can also change its name using `.alias()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ek7nCcIryoC",
        "outputId": "e24796fc-363e-42dd-ddc1-eaa054980835"
      },
      "source": [
        "df2.select(df2['bw'].cast(types.FloatType()).alias('yuhuuu')).show()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+\n",
            "| yuhuuu|\n",
            "+-------+\n",
            "|   18.0|\n",
            "|25000.0|\n",
            "|   14.0|\n",
            "|25000.0|\n",
            "|   14.0|\n",
            "|   18.0|\n",
            "|25000.0|\n",
            "|   14.0|\n",
            "|25000.0|\n",
            "|   18.0|\n",
            "|25000.0|\n",
            "|25000.0|\n",
            "|   18.0|\n",
            "| 8000.0|\n",
            "|25000.0|\n",
            "+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2vcDcT1ryoC"
      },
      "source": [
        "### Summary statistics\n",
        "\n",
        "https://databricks.com/blog/2015/06/02/statistical-and-mathematical-functions-with-dataframes-in-spark.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awzruFATryoD",
        "outputId": "8bc69528-e003-4086-cfa4-fe2344d4806b"
      },
      "source": [
        "df2.stat.corr('id', 'bw')"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18822612115250825"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2LklKYdJQ5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fef79732-aa02-4696-b60a-103d95778a88"
      },
      "source": [
        "df2.stat.cov('id', 'bw')"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10560.857142857145"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMZDwK7NJXMT",
        "outputId": "862708da-bcbb-4828-900f-82dd47f65c40"
      },
      "source": [
        "df2.stat.approxQuantile('bw', [.2, .4], 1e-4)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[14.0, 18.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2k3rLYiryoD"
      },
      "source": [
        "### .crosstab()\n",
        "\n",
        "Crosstab returns the contingency table for two columns, as a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NZL2cMMKOQR",
        "outputId": "48414adf-c7b7-453c-b303-be03038c0e3e"
      },
      "source": [
        "random.seed(12)\n",
        "\n",
        "@functions.udf\n",
        "def enclosure():\n",
        "  return random.choice(['froopyland', 'magic kingdom'])\n",
        "\n",
        "df3 = df2.withColumn('enclosure', enclosure())\n",
        "df3.cache().show()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------------+-----+-------------+\n",
            "| id|       species|   bw|    enclosure|\n",
            "+---+--------------+-----+-------------+\n",
            "|  0|naked mole rat|   18|magic kingdom|\n",
            "|  1|      capibara|25000|magic kingdom|\n",
            "|  2|       axolotl|   14|   froopyland|\n",
            "|  3|      capibara|25000|   froopyland|\n",
            "|  4|       axolotl|   14|magic kingdom|\n",
            "|  5|naked mole rat|   18|   froopyland|\n",
            "|  6|      capibara|25000|   froopyland|\n",
            "|  7|       axolotl|   14|   froopyland|\n",
            "|  8|      capibara|25000|magic kingdom|\n",
            "|  9|naked mole rat|   18|magic kingdom|\n",
            "| 10|      capibara|25000|magic kingdom|\n",
            "| 11|      capibara|25000|magic kingdom|\n",
            "| 12|naked mole rat|   18|magic kingdom|\n",
            "| 13|    flying fox| 8000|magic kingdom|\n",
            "| 14|      capibara|25000|   froopyland|\n",
            "+---+--------------+-----+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPKUkAI8ryoD",
        "outputId": "21d493c1-5afb-4046-9d8c-3d297c7553ea"
      },
      "source": [
        "df3.stat.crosstab('species', 'enclosure').show()"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+----------+-------------+\n",
            "|species_enclosure|froopyland|magic kingdom|\n",
            "+-----------------+----------+-------------+\n",
            "|   naked mole rat|         1|            3|\n",
            "|         capibara|         3|            4|\n",
            "|       flying fox|         0|            1|\n",
            "|          axolotl|         2|            1|\n",
            "+-----------------+----------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goaLBWODryoD"
      },
      "source": [
        "### Grouping\n",
        "\n",
        "Grouping works very similarly to Pandas: executing groupby (or groupBy) on a DataFrame will return an object (a GroupedData) that can then be aggregated to obtain the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twlF0as6ryoD",
        "outputId": "19853b53-7e28-4f2a-8168-bbf7c7213b2e"
      },
      "source": [
        "df3.groupby('species')\\\n",
        "   .agg(functions.max('id').alias('max_id'),\n",
        "        functions.min('id').alias('min_id'))\\\n",
        "   .show()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+------+------+\n",
            "|       species|max_id|min_id|\n",
            "+--------------+------+------+\n",
            "|      capibara|    14|     1|\n",
            "|       axolotl|     7|     2|\n",
            "|    flying fox|    13|    13|\n",
            "|naked mole rat|    12|     0|\n",
            "+--------------+------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhFNR1zPMGo_",
        "outputId": "c9797413-2d33-49ab-ce95-8a3ea76c20dd"
      },
      "source": [
        "df3"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id: smallint, species: string, bw: int, enclosure: string]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqnwMA6bryoE"
      },
      "source": [
        "GroupedData has several aggregation functions defined:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXj_TEmmryoE",
        "outputId": "65d133ed-5b2e-4974-a281-2eb70697727f"
      },
      "source": [
        "grouped_data = df3.groupby('species')\n",
        "grouped_data.max()"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[species: string, max(id): smallint, max(bw): int]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRVoT83ZryoE"
      },
      "source": [
        "We can do several aggregations in a single step, with a number of different syntaxes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhWWZUgdryoE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCd-vXORryoE"
      },
      "source": [
        "### Intersections\n",
        "\n",
        "Ver much like SQL joins. We can specify the columns and the join method (left, right, inner, outer) or we can let Spark infer them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYNQ521WryoF",
        "outputId": "4468d85b-3630-41e6-a5ee-e538956cbbb7"
      },
      "source": [
        "random.seed(12)\n",
        "\n",
        "data = list(zip(random.choices(['froopyland', 'magic kingdom', 'neverland'], k = 10),\n",
        "                 random.choices([3,5,7, None], k=10)))\n",
        "\n",
        "data\n",
        "\n",
        "other_df = spark.createDataFrame(data, schema=['enclosure', 'id'])\n",
        "other_df"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[enclosure: string, id: bigint]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_HiRgq3ryoF"
      },
      "source": [
        "Spark refuses to do cross joins by default. To perform them, we can \n",
        "\n",
        "a) Allow then explicitly:\n",
        "\n",
        "```python\n",
        "spark.conf.set(\"spark.sql.crossJoin.enabled\", \"true\")\n",
        "```\n",
        "\n",
        "b) Specify the join criterion\n",
        "\n",
        "```python\n",
        "df4.join(new_df, on='id').show()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "raises-exception"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iKN4o_4ryoF",
        "outputId": "7fa5d06a-fd2b-4576-e85c-96467f5accfd"
      },
      "source": [
        "df3.join(other_df).count() # Cross join"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD07gBvLOkfP",
        "outputId": "9f100d62-26de-4575-f78f-6f819d36d0dc"
      },
      "source": [
        "duplicate_columns = df3.join(other_df, on='enclosure', how='inner')\n",
        "duplicate_columns.show()"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------+---+--------------+-----+---+\n",
            "|    enclosure| id|       species|   bw| id|\n",
            "+-------------+---+--------------+-----+---+\n",
            "|magic kingdom| 13|    flying fox| 8000|  7|\n",
            "|magic kingdom| 12|naked mole rat|   18|  7|\n",
            "|magic kingdom| 11|      capibara|25000|  7|\n",
            "|magic kingdom| 10|      capibara|25000|  7|\n",
            "|magic kingdom|  9|naked mole rat|   18|  7|\n",
            "|magic kingdom|  8|      capibara|25000|  7|\n",
            "|magic kingdom|  4|       axolotl|   14|  7|\n",
            "|magic kingdom|  1|      capibara|25000|  7|\n",
            "|magic kingdom|  0|naked mole rat|   18|  7|\n",
            "|magic kingdom| 13|    flying fox| 8000|  7|\n",
            "|magic kingdom| 12|naked mole rat|   18|  7|\n",
            "|magic kingdom| 11|      capibara|25000|  7|\n",
            "|magic kingdom| 10|      capibara|25000|  7|\n",
            "|magic kingdom|  9|naked mole rat|   18|  7|\n",
            "|magic kingdom|  8|      capibara|25000|  7|\n",
            "|magic kingdom|  4|       axolotl|   14|  7|\n",
            "|magic kingdom|  1|      capibara|25000|  7|\n",
            "|magic kingdom|  0|naked mole rat|   18|  7|\n",
            "|magic kingdom| 13|    flying fox| 8000|  3|\n",
            "|magic kingdom| 12|naked mole rat|   18|  3|\n",
            "+-------------+---+--------------+-----+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPduVrIPO-6E",
        "outputId": "b3799c8e-709e-4f44-b272-e8fbaa40e261"
      },
      "source": [
        "duplicate_columns.select(other_df['id']).show()"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+\n",
            "| id|\n",
            "+---+\n",
            "|  7|\n",
            "|  7|\n",
            "|  7|\n",
            "|  7|\n",
            "|  7|\n",
            "|  7|\n",
            "|  7|\n",
            "|  7|\n",
            "|  7|\n",
            "|  7|\n",
            "|  7|\n",
            "|  7|\n",
            "|  7|\n",
            "|  7|\n",
            "|  7|\n",
            "|  7|\n",
            "|  7|\n",
            "|  7|\n",
            "|  3|\n",
            "|  3|\n",
            "+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oovKwhm9OwLO",
        "outputId": "0f54f64e-2ed9-4068-a736-1b3a84736754"
      },
      "source": [
        "df3.join(other_df, on=['enclosure', 'id'], how='inner').show()"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+---+--------------+-----+\n",
            "| enclosure| id|       species|   bw|\n",
            "+----------+---+--------------+-----+\n",
            "|froopyland|  5|naked mole rat|   18|\n",
            "|froopyland|  3|      capibara|25000|\n",
            "|froopyland|  3|      capibara|25000|\n",
            "+----------+---+--------------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "wBlrOtQyryoF"
      },
      "source": [
        "#### Digression\n",
        "\n",
        "We can monitor our running jobs and storage used at the Spark Web UI. We can get its url with sc.uiWebUrl.\n",
        "\n",
        "StorageLevels represent how our DataFrame is cached: we can save the results of the computation up to that point, so that if we process several times the same data only the subsequent steps will be recomputed.\n",
        "\n",
        "In Google Colab, we need to do additional work to expose it. We need a Spark session with a web UI port other than 4040. In this example we are using 4050.\n",
        "\n",
        "\n",
        "```python\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -qq ngrok-stable-linux-amd64.zip\n",
        "get_ipython().system_raw('./ngrok http 4050 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "```        \n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acg8ZWfkryoG"
      },
      "source": [
        "We can erase it with `unpersist`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQgHd5tcryoG"
      },
      "source": [
        "#### Exercise\n",
        "\n",
        "Calculate the [z-score](http://www.statisticshowto.com/probability-and-statistics/z-score/) of each creature's body weight for their enclosure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBb_1VlyryoH",
        "outputId": "88098941-ba44-415a-815f-032e02db0ad6"
      },
      "source": [
        "df3.show()"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------------+-----+-------------+\n",
            "| id|       species|   bw|    enclosure|\n",
            "+---+--------------+-----+-------------+\n",
            "|  0|naked mole rat|   18|magic kingdom|\n",
            "|  1|      capibara|25000|magic kingdom|\n",
            "|  2|       axolotl|   14|   froopyland|\n",
            "|  3|      capibara|25000|   froopyland|\n",
            "|  4|       axolotl|   14|magic kingdom|\n",
            "|  5|naked mole rat|   18|   froopyland|\n",
            "|  6|      capibara|25000|   froopyland|\n",
            "|  7|       axolotl|   14|   froopyland|\n",
            "|  8|      capibara|25000|magic kingdom|\n",
            "|  9|naked mole rat|   18|magic kingdom|\n",
            "| 10|      capibara|25000|magic kingdom|\n",
            "| 11|      capibara|25000|magic kingdom|\n",
            "| 12|naked mole rat|   18|magic kingdom|\n",
            "| 13|    flying fox| 8000|magic kingdom|\n",
            "| 14|      capibara|25000|   froopyland|\n",
            "+---+--------------+-----+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNy2c955ryoH"
      },
      "source": [
        "1) Calculate the mean and std of hitpoints for each location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM_Mbju_ryoH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EqFn2tIryoH"
      },
      "source": [
        "2) Annotate each creature with the stats corresponding to their location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9rXdIaAryoH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQvKqqMCryoI"
      },
      "source": [
        "3) Calculate the z-score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3QYDSy6ryoI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jG8UB7KryoI"
      },
      "source": [
        "Note that we can build more complex boolean conditions for joining, as well as joining on columns that do not have the same name:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzquu1HrryoI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i40wqC5-ryoI"
      },
      "source": [
        "### Handling null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJjakJmLryoJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv7dIlooryoJ"
      },
      "source": [
        "## SQL querying\n",
        "\n",
        "We need to register our DataFrame as a table in the SQL context in order to be able to query against it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNU0Ts5nryoJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3X0Te1pryoJ"
      },
      "source": [
        "Once registered, we can perform queries as complex as we want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx2rdsMCryoJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o_YPrCnryoK"
      },
      "source": [
        "## Interoperation with Pandas\n",
        "\n",
        "Easy peasy. We can convert a spark DataFrame into a Pandas one, which will `collect` it, and viceversa, which will distribute it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubg_g0KxryoK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76YsCn9PryoK"
      },
      "source": [
        "## Writing out\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIqSl2UGryoK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJilTfVFryoL"
      },
      "source": [
        "#### Exercise\n",
        "\n",
        "Repeat the exercise from the previous notebook, but this time with DataFrames.\n",
        "\n",
        "Get stats for all tickets with destination MAD from `coupons150720.csv`.\n",
        "\n",
        "You will need to extract ticket amounts with destination MAD, and then calculate:\n",
        "\n",
        "1. Total ticket amounts per origin\n",
        "2. Top 10 airlines by average amount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEin_xBIryoL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cn5929eryoL"
      },
      "source": [
        "1) Extract the fields you need (c0,c1,c2,c3,c4 and c6) into a dataframe with proper names and types\n",
        "\n",
        "Remember, you want to calculate:\n",
        "\n",
        "Total ticket amounts per origin\n",
        "\n",
        "Top 10 airlines by average amount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hV2xkBOryoL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmt1QvFnryoL"
      },
      "source": [
        "2) Total ticket amounts per origin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m034x4ysryoM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcZs5TbFryoM"
      },
      "source": [
        "3) Top 10 Airlines by average amount\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ASFAZswryoM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY7HYJo7ryoM"
      },
      "source": [
        "## Further Reading\n",
        "\n",
        "https://databricks.com/blog/2016/07/14/a-tale-of-three-apache-spark-apis-rdds-dataframes-and-datasets.html\n",
        "\n",
        "https://www.datacamp.com/community/tutorials/apache-spark-python\n",
        "\n",
        "https://spark.apache.org/docs/2.2.0/sql-programming-guide.html\n",
        "\n",
        "https://ogirardot.wordpress.com/2015/05/29/rdds-are-the-new-bytecode-of-apache-spark/\n",
        "\n",
        "https://stackoverflow.com/questions/36822224/what-are-the-pros-and-cons-of-parquet-format-compared-to-other-formats\n",
        "\n",
        "https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf"
      ]
    }
  ]
}